{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed9d49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self):\n",
    "        self.medians_asds = []\n",
    "        \n",
    "\n",
    "    def train(self, data, normal_feature_names, cat_feature_names, sorted_lists, \\\n",
    "                  one_hot_feature_names, feature_names):\n",
    "\n",
    "        # The features that are not supposed to be changed, need to be converted in float \n",
    "        for feature in feature_names:\n",
    "            if feature in cat_feature_names or feature in one_hot_feature_names:\n",
    "                continue\n",
    "            data[feature] = list(map(float, data[feature]))\n",
    "\n",
    "        for feature_name in normal_feature_names:\n",
    "            self.normalize_feature(data, feature_name)\n",
    "\n",
    "        i=0\n",
    "        for feature_name in cat_feature_names:\n",
    "            self.cat_to_num(data, feature_name, sorted_lists[i])\n",
    "            i+=1\n",
    "\n",
    "        for feature_name in one_hot_feature_names:\n",
    "            self.one_hot_convert(data, feature_name)\n",
    "\n",
    "\n",
    "    # converts a categorical feature into a numarical one in an inplace way\n",
    "    def cat_to_num(self, data, feature_name, sorted_values):\n",
    "        #values = list(set( data[feature_name] ))\n",
    "        cat_num={}\n",
    "        for num in range(len(sorted_values)):\n",
    "            cat_num[sorted_values[num]] = num\n",
    "\n",
    "        for i in range(len(data[feature_name])):\n",
    "            data[feature_name][i] = cat_num[ data[feature_name][i] ]\n",
    "    \n",
    "\n",
    "    # replace a categorical feature with multiple features \n",
    "    # using one hot encoding in an inplace way\n",
    "    def one_hot_convert(self, data, feature_name):\n",
    "        values = list(set( data[feature_name] ))\n",
    "        cat_num={}\n",
    "        for num in range(len(values)):\n",
    "            cat_num[values[num]] = num + 1\n",
    "\n",
    "        for v in values:\n",
    "            data[str(feature_name) + '_' + str(cat_num[v])] = []\n",
    "\n",
    "        for i in range(len(data[feature_name])):\n",
    "            for v in values:\n",
    "                data[str(feature_name) + '_' + str(cat_num[v])].append(1 if data[feature_name][i] == v else 0)\n",
    "\n",
    "        del data[feature_name]\n",
    "\n",
    "\n",
    "    def normalize_feature(self, data, feature_name):\n",
    "        median = self.getMedian(data[feature_name])\n",
    "        asd = self.get_absolute_standard_deviation(data[feature_name], median)\n",
    "        #print(\"Median: %f   ASD = %f\" % (median, asd))\n",
    "        self.medians_asds.append((median, asd))\n",
    "        for i in range(len(data[feature_name])):\n",
    "            data[feature_name][i] = (data[feature_name][i] - median) / asd\n",
    "\n",
    "\n",
    "    #returns the median of list l\n",
    "    def getMedian(self, l):\n",
    "        if l == []:\n",
    "            return []\n",
    "        sorted_l = sorted(l)\n",
    "        length = len(l)\n",
    "        if length % 2 == 1: # length of list is odd so return middle element\n",
    "            return sorted_l[int(((length + 1) / 2) -  1)]\n",
    "        else: # length of list is even so compute midpoint\n",
    "            v1 = sorted_l[int(length / 2)]\n",
    "            v2 =sorted_l[(int(length / 2) - 1)]\n",
    "            return (v1 + v2) / 2.0\n",
    "    \n",
    "\n",
    "    # computes standard deviation\n",
    "    def get_absolute_standard_deviation(self, l, median):\n",
    "        return sum([abs(item - median) for item in l]) / len(l)\n",
    "\n",
    "\n",
    "\n",
    "    def test(self, test_data, data, normal_feature_names, cat_feature_names, \\\n",
    "             sorted_lists, one_hot_feature_names, feature_names, label_name, k=3):\n",
    "        predictions = []\n",
    "\n",
    "        # The features that are not supposed to be changed, need to be converted in float \n",
    "        for feature in feature_names:\n",
    "            if feature in cat_feature_names or feature in one_hot_feature_names:\n",
    "                continue\n",
    "            test_data[feature] = list(map(float, test_data[feature]))\n",
    "\n",
    "        for feature_name in normal_feature_names:\n",
    "            self.normalize_feature(test_data, feature_name)\n",
    "\n",
    "        i=0\n",
    "        for feature_name in cat_feature_names:\n",
    "            self.cat_to_num(test_data, feature_name, sorted_lists[i])\n",
    "            i+=1\n",
    "\n",
    "        for feature_name in one_hot_feature_names:\n",
    "            self.one_hot_convert(test_data, feature_name)\n",
    "\n",
    "        # make a prediction for every instance\n",
    "        feature_names = list(test_data.keys())\n",
    "        feature_names.remove(label_name)\n",
    "        length = len(test_data[ feature_names[0] ])\n",
    "        for i in range(length):\n",
    "            test_instance = [ test_data[feature][i] for feature in feature_names ]\n",
    "            predictions.append(self.classify(data, feature_names, label_name, test_instance, k))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    # Computes the Manhattan distance.\n",
    "    def manhattan(self, vector1, vector2):\n",
    "        return sum(map(lambda v1, v2: abs(v1 - v2), vector1, vector2))\n",
    "\n",
    "\n",
    "\n",
    "    # compute the cosine similarity of x,y\n",
    "    def cosine_x_y(self, x,y):\n",
    "        if x.count(0) == len(x) or y.count(0) == len(y): # All vector's values are zero\n",
    "            return -2 # Indecating that similarity can't be computed\n",
    "        numerator = sum([t[0]*t[1] for t in zip(x, y)])\n",
    "        denominator = sqrt( sum([i * i for i in x]) ) * sqrt( sum([i * i for i in y]) )\n",
    "        return numerator/denominator\n",
    "\n",
    "\n",
    "\n",
    "    def classify(self, data, feature_names, label_name, test_instance, k):\n",
    "        neighbors = []\n",
    "        for i in range( len(data[label_name]) ):\n",
    "            instance = [ data[feature][i] for feature in feature_names ]\n",
    "            neighbors.append( (self.manhattan(instance, test_instance), i) )\n",
    "\n",
    "        neighbors_labels = [ data[label_name][item[1]] for item in sorted(neighbors)[:k] ]\n",
    "        return max(set(neighbors_labels), key=neighbors_labels.count)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6780cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values of a list with a new item if they exist in o_items\n",
    "def replace_items(l, o_items, n_item):\n",
    "    return [n_item if item in o_items else item for item in l]\n",
    "\n",
    "# fill missing values in missing_feature with most frequent value per class\n",
    "def fill_missing(data, label_name, missing_feature, missing_value):\n",
    "    best_filling = {}\n",
    "    for klass in list(set(data[label_name])):\n",
    "        best_filling[klass] = []\n",
    "\n",
    "    for i in range(len(data[label_name])):\n",
    "        best_filling[data[label_name][i]].append(data[missing_feature][i])\n",
    "\n",
    "    for klass, values in best_filling.items():\n",
    "        best_filling[klass] = max(set(values), key=values.count)\n",
    "\n",
    "    for i in range(len(data[missing_feature])):\n",
    "        if data[missing_feature][i] == missing_value:\n",
    "            data[missing_feature][i] = best_filling[data[label_name][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1485ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790525b0",
   "metadata": {},
   "source": [
    "# breast-cancer-wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82809184",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61a44862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017699115044248"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=10)\n",
    "y = df[10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33) \n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "feature_names.remove(0)\n",
    "normal_feature_names = feature_names\n",
    "cat_feature_names = []\n",
    "one_hot_feature_names = []\n",
    "\n",
    "\n",
    "classifier = KNN()\n",
    "classifier.train(d_demo, normal_feature_names, cat_feature_names, [], one_hot_feature_names, feature_names)\n",
    "my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, [], \n",
    "                   one_hot_feature_names, feature_names, label_name, k=3)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048ac8c",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7335d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.6204379562043796\n",
      "fold:  2 ===> accuracy:  0.6277372262773723\n",
      "fold:  3 ===> accuracy:  0.5985401459854015\n",
      "fold:  4 ===> accuracy:  0.6323529411764706\n",
      "fold:  5 ===> accuracy:  0.6397058823529411\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.6058394160583942\n",
      "fold:  2 ===> accuracy:  0.635036496350365\n",
      "fold:  3 ===> accuracy:  0.5693430656934306\n",
      "fold:  4 ===> accuracy:  0.6397058823529411\n",
      "fold:  5 ===> accuracy:  0.5808823529411765\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.583941605839416\n",
      "fold:  2 ===> accuracy:  0.635036496350365\n",
      "fold:  3 ===> accuracy:  0.5693430656934306\n",
      "fold:  4 ===> accuracy:  0.6323529411764706\n",
      "fold:  5 ===> accuracy:  0.6691176470588235\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.6423357664233577\n",
      "fold:  2 ===> accuracy:  0.5766423357664233\n",
      "fold:  3 ===> accuracy:  0.5547445255474452\n",
      "fold:  4 ===> accuracy:  0.625\n",
      "fold:  5 ===> accuracy:  0.6323529411764706\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.6204379562043796\n",
      "fold:  2 ===> accuracy:  0.6204379562043796\n",
      "fold:  3 ===> accuracy:  0.635036496350365\n",
      "fold:  4 ===> accuracy:  0.5588235294117647\n",
      "fold:  5 ===> accuracy:  0.6691176470588235\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.5547445255474452\n",
      "fold:  2 ===> accuracy:  0.6204379562043796\n",
      "fold:  3 ===> accuracy:  0.6204379562043796\n",
      "fold:  4 ===> accuracy:  0.6397058823529411\n",
      "fold:  5 ===> accuracy:  0.6397058823529411\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.635036496350365\n",
      "fold:  2 ===> accuracy:  0.6058394160583942\n",
      "fold:  3 ===> accuracy:  0.656934306569343\n",
      "fold:  4 ===> accuracy:  0.5808823529411765\n",
      "fold:  5 ===> accuracy:  0.5588235294117647\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.6788321167883211\n",
      "fold:  2 ===> accuracy:  0.5547445255474452\n",
      "fold:  3 ===> accuracy:  0.5985401459854015\n",
      "fold:  4 ===> accuracy:  0.5882352941176471\n",
      "fold:  5 ===> accuracy:  0.6176470588235294\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.5985401459854015\n",
      "fold:  2 ===> accuracy:  0.6277372262773723\n",
      "fold:  3 ===> accuracy:  0.5912408759124088\n",
      "fold:  4 ===> accuracy:  0.6029411764705882\n",
      "fold:  5 ===> accuracy:  0.6029411764705882\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.5985401459854015\n",
      "fold:  2 ===> accuracy:  0.635036496350365\n",
      "fold:  3 ===> accuracy:  0.6058394160583942\n",
      "fold:  4 ===> accuracy:  0.6397058823529411\n",
      "fold:  5 ===> accuracy:  0.6691176470588235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "target = df[10]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=10)\n",
    "        y = train[10]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        feature_names.remove(0)\n",
    "        \n",
    "        X_test = test.drop(columns=10)\n",
    "        y_test = test[10]\n",
    "        d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "        \n",
    "\n",
    "        normal_feature_names = feature_names\n",
    "        cat_feature_names = []\n",
    "        sorted_lists = []\n",
    "        one_hot_feature_names = []\n",
    "        \n",
    "        classifier = KNN()\n",
    "        classifier.train(d_demo, normal_feature_names, cat_feature_names, [], one_hot_feature_names, feature_names)\n",
    "        my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, [], \n",
    "                           one_hot_feature_names, feature_names, label_name, k=3)     \n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dad9750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2f02cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.03222847194400608\n",
      "Mean:  0.6139297981966509\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e365c",
   "metadata": {},
   "source": [
    "# car dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50b0e8",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d954633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9132947976878613"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./car.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=6)\n",
    "y = df[6]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_demo[2] = replace_items(d_demo[2], '5more', '5')\n",
    "d_demo[3] = replace_items(d_demo[3], 'more', '3')\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "normal_feature_names = [2, 3]\n",
    "cat_feature_names = [0, 1, 4, 5]\n",
    "sorted_lists = [['low', 'med', 'high', 'vhigh'], \n",
    "                ['low', 'med', 'high', 'vhigh'], \n",
    "                ['small', 'med', 'big'], \n",
    "                ['low', 'med', 'high']]\n",
    "one_hot_feature_names = []\n",
    "d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "d_test[2] = replace_items(d_test[2], '5more', '5')\n",
    "d_test[3] = replace_items(d_test[3], 'more', '3')\n",
    "\n",
    "classifier = KNN()\n",
    "classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, one_hot_feature_names, feature_names)\n",
    "my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, sorted_lists, \n",
    "                   one_hot_feature_names, feature_names, label_name, k=3)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9f81a",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fae7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.8786127167630058\n",
      "fold:  2 ===> accuracy:  0.846820809248555\n",
      "fold:  3 ===> accuracy:  0.8901734104046243\n",
      "fold:  4 ===> accuracy:  0.9159420289855073\n",
      "fold:  5 ===> accuracy:  0.9014492753623189\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.9248554913294798\n",
      "fold:  2 ===> accuracy:  0.9075144508670521\n",
      "fold:  3 ===> accuracy:  0.8757225433526011\n",
      "fold:  4 ===> accuracy:  0.8666666666666667\n",
      "fold:  5 ===> accuracy:  0.8695652173913043\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.8959537572254336\n",
      "fold:  2 ===> accuracy:  0.9017341040462428\n",
      "fold:  3 ===> accuracy:  0.8988439306358381\n",
      "fold:  4 ===> accuracy:  0.8956521739130435\n",
      "fold:  5 ===> accuracy:  0.8782608695652174\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.9017341040462428\n",
      "fold:  2 ===> accuracy:  0.8901734104046243\n",
      "fold:  3 ===> accuracy:  0.8815028901734104\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.881159420289855\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.8901734104046243\n",
      "fold:  2 ===> accuracy:  0.8815028901734104\n",
      "fold:  3 ===> accuracy:  0.8641618497109826\n",
      "fold:  4 ===> accuracy:  0.9043478260869565\n",
      "fold:  5 ===> accuracy:  0.9159420289855073\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.8641618497109826\n",
      "fold:  2 ===> accuracy:  0.8988439306358381\n",
      "fold:  3 ===> accuracy:  0.8872832369942196\n",
      "fold:  4 ===> accuracy:  0.9101449275362319\n",
      "fold:  5 ===> accuracy:  0.8985507246376812\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.8786127167630058\n",
      "fold:  2 ===> accuracy:  0.8930635838150289\n",
      "fold:  3 ===> accuracy:  0.869942196531792\n",
      "fold:  4 ===> accuracy:  0.8956521739130435\n",
      "fold:  5 ===> accuracy:  0.9014492753623189\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.8901734104046243\n",
      "fold:  2 ===> accuracy:  0.884393063583815\n",
      "fold:  3 ===> accuracy:  0.8872832369942196\n",
      "fold:  4 ===> accuracy:  0.8724637681159421\n",
      "fold:  5 ===> accuracy:  0.8840579710144928\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.9104046242774566\n",
      "fold:  2 ===> accuracy:  0.9017341040462428\n",
      "fold:  3 ===> accuracy:  0.8959537572254336\n",
      "fold:  4 ===> accuracy:  0.8405797101449275\n",
      "fold:  5 ===> accuracy:  0.9159420289855073\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.8872832369942196\n",
      "fold:  2 ===> accuracy:  0.8352601156069365\n",
      "fold:  3 ===> accuracy:  0.8641618497109826\n",
      "fold:  4 ===> accuracy:  0.8956521739130435\n",
      "fold:  5 ===> accuracy:  0.9014492753623189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "df = pd.read_csv('./car.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "target = df[6]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=6)\n",
    "        y = train[6]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        d_demo[2] = replace_items(d_demo[2], '5more', '5')\n",
    "        d_demo[3] = replace_items(d_demo[3], 'more', '3')\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        \n",
    "        X_test = test.drop(columns=6)\n",
    "        y_test = test[6]\n",
    "        d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "        d_test[2] = replace_items(d_test[2], '5more', '5')\n",
    "        d_test[3] = replace_items(d_test[3], 'more', '3')\n",
    "        \n",
    "        normal_feature_names = [2, 3]\n",
    "        cat_feature_names = [0, 1, 4, 5]\n",
    "        sorted_lists = [['low', 'med', 'high', 'vhigh'], \n",
    "                ['low', 'med', 'high', 'vhigh'], \n",
    "                ['small', 'med', 'big'], \n",
    "                ['low', 'med', 'high']]        \n",
    "        one_hot_feature_names = []\n",
    "        \n",
    "        classifier = KNN()\n",
    "        classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, \\\n",
    "                         one_hot_feature_names, feature_names)\n",
    "        my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, \\\n",
    "                                  sorted_lists, one_hot_feature_names, feature_names, \\\n",
    "                                  label_name, k=3)       \n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f66e73f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54eb7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.018918009892190116\n",
      "Mean:  0.8883143168300243\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8722d1",
   "metadata": {},
   "source": [
    "# mushroom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438340a9",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cc411cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "feature_names.remove(16)\n",
    "normal_feature_names = []\n",
    "cat_feature_names = []\n",
    "sorted_lists = []\n",
    "one_hot_feature_names = feature_names\n",
    "#d_test = X_test.to_dict(orient=\"list\")\n",
    "d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "fill_missing(d_demo, label_name, 11, '?')\n",
    "fill_missing(d_test, label_name, 11, '?')\n",
    "del d_demo[16]\n",
    "del d_test[16]\n",
    "\n",
    "classifier = KNN()\n",
    "classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, one_hot_feature_names, feature_names)\n",
    "my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, sorted_lists, \n",
    "                   one_hot_feature_names, feature_names, label_name, k=3)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e16f7",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6b6a1",
   "metadata": {},
   "source": [
    "**It takes a long time**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab6952",
   "metadata": {},
   "source": [
    "# ecoli dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d37b28",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4e1afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8828828828828829"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=8)\n",
    "y = df[8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "#d_test = X_test.to_dict(orient=\"list\")\n",
    "d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "del d_demo[0]\n",
    "del d_test[0]\n",
    "feature_names.remove(0)\n",
    "normal_feature_names = []\n",
    "#cat_feature_names = [ feature_names[i] for i in [3,4] ]\n",
    "#sorted_lists = [['0.48', '1.0'], \n",
    "#                [0.5, '1.0']]\n",
    "cat_feature_names = []\n",
    "sorted_lists = []\n",
    "one_hot_feature_names = []\n",
    "\n",
    "classifier = KNN()\n",
    "classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, one_hot_feature_names, feature_names)\n",
    "my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, sorted_lists, \n",
    "                   one_hot_feature_names, feature_names, label_name, k=3)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2bf58a",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f842a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.8235294117647058\n",
      "fold:  2 ===> accuracy:  0.8656716417910447\n",
      "fold:  3 ===> accuracy:  0.8208955223880597\n",
      "fold:  4 ===> accuracy:  0.835820895522388\n",
      "fold:  5 ===> accuracy:  0.8955223880597015\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.8235294117647058\n",
      "fold:  2 ===> accuracy:  0.8805970149253731\n",
      "fold:  3 ===> accuracy:  0.7910447761194029\n",
      "fold:  4 ===> accuracy:  0.8656716417910447\n",
      "fold:  5 ===> accuracy:  0.9104477611940298\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.8676470588235294\n",
      "fold:  2 ===> accuracy:  0.8059701492537313\n",
      "fold:  3 ===> accuracy:  0.8955223880597015\n",
      "fold:  4 ===> accuracy:  0.8059701492537313\n",
      "fold:  5 ===> accuracy:  0.8507462686567164\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.835820895522388\n",
      "fold:  3 ===> accuracy:  0.7164179104477612\n",
      "fold:  4 ===> accuracy:  0.8656716417910447\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.8382352941176471\n",
      "fold:  2 ===> accuracy:  0.7313432835820896\n",
      "fold:  3 ===> accuracy:  0.835820895522388\n",
      "fold:  4 ===> accuracy:  0.8059701492537313\n",
      "fold:  5 ===> accuracy:  0.9253731343283582\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.8805970149253731\n",
      "fold:  3 ===> accuracy:  0.7761194029850746\n",
      "fold:  4 ===> accuracy:  0.8805970149253731\n",
      "fold:  5 ===> accuracy:  0.7761194029850746\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.8805970149253731\n",
      "fold:  3 ===> accuracy:  0.7910447761194029\n",
      "fold:  4 ===> accuracy:  0.7910447761194029\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.8676470588235294\n",
      "fold:  2 ===> accuracy:  0.8955223880597015\n",
      "fold:  3 ===> accuracy:  0.8955223880597015\n",
      "fold:  4 ===> accuracy:  0.8656716417910447\n",
      "fold:  5 ===> accuracy:  0.746268656716418\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.8507462686567164\n",
      "fold:  3 ===> accuracy:  0.8208955223880597\n",
      "fold:  4 ===> accuracy:  0.8208955223880597\n",
      "fold:  5 ===> accuracy:  0.7910447761194029\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.9402985074626866\n",
      "fold:  3 ===> accuracy:  0.8208955223880597\n",
      "fold:  4 ===> accuracy:  0.835820895522388\n",
      "fold:  5 ===> accuracy:  0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "target = df[0]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=8)\n",
    "        y = train[8]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        \n",
    "        X_test = test.drop(columns=8)\n",
    "        y_test = test[8]\n",
    "        d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        del d_demo[0]\n",
    "        del d_test[0]\n",
    "        feature_names.remove(0)\n",
    "        normal_feature_names = []\n",
    "        #cat_feature_names = [ feature_names[i] for i in [3,4] ]\n",
    "        #sorted_lists = [['0.48', '1.0'], \n",
    "        #                [0.5, '1.0']]\n",
    "        cat_feature_names = []\n",
    "        sorted_lists = []\n",
    "        one_hot_feature_names = []\n",
    "        \n",
    "        classifier = KNN()\n",
    "        classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, one_hot_feature_names, feature_names)\n",
    "        my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, sorted_lists, \n",
    "                           one_hot_feature_names, feature_names, label_name, k=3)       \n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28e2d89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "108e2481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.04997225500068545\n",
      "Mean:  0.84486391571554\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c893e1",
   "metadata": {},
   "source": [
    "# letter-recognition dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d92df",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e17fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "normal_feature_names = feature_names\n",
    "cat_feature_names = []\n",
    "one_hot_feature_names = []\n",
    "sorted_lists = []\n",
    "d_test = pd.concat([X_test, y_test], axis=1).to_dict(orient='list')\n",
    "\n",
    "classifier = KNN()\n",
    "classifier.train(d_demo, normal_feature_names, cat_feature_names, sorted_lists, one_hot_feature_names, feature_names)\n",
    "my_pred = classifier.test(d_test, d_demo, normal_feature_names, cat_feature_names, sorted_lists, \n",
    "                   one_hot_feature_names, feature_names, label_name, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb6d0101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443939393939393"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42968d19",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dddbe",
   "metadata": {},
   "source": [
    "**It takes a long time**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
