{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08b62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NB:\n",
    "    def __init__(self):\n",
    "        self.classes = {}\n",
    "        # counts used for attributes that are not numeric\n",
    "        self.counts = {}\n",
    "        # totals used for attributes that are numereric\n",
    "        # we will use these to compute the mean and ssd for each attribute - class pair.\n",
    "        self.totals = {}\n",
    "        self.priors = {}\n",
    "        self.conditional = {}\n",
    "        self.means = {}\n",
    "        self.ssds = {}\n",
    "\n",
    "\n",
    "    def train(self, data, cat_feature_names, num_feature_names, label_name):\n",
    "        for i in range(len(data[label_name])):\n",
    "            # now process this instance\n",
    "            current_calss = data[label_name][i]\n",
    "            self.classes.setdefault(current_calss, 0)\n",
    "            self.classes[current_calss] += 1\n",
    "            self.counts.setdefault(current_calss, {})\n",
    "            self.totals.setdefault(current_calss, {})\n",
    "            # now process each non-numeric attribute of the instance\n",
    "            for col in cat_feature_names:\n",
    "                self.counts[current_calss].setdefault(col, {})\n",
    "                self.counts[current_calss][col].setdefault(data[col][i], 0)\n",
    "                self.counts[current_calss][col][data[col][i]] += 1\n",
    "            # process numeric attributes\n",
    "            for col in num_feature_names:\n",
    "                self.totals[current_calss].setdefault(col, 0)\n",
    "                self.totals[current_calss][col] += data[col][i]\n",
    "\n",
    "        # ok done counting. now compute probabilities\n",
    "\n",
    "        # first prior probabilities p(h)\n",
    "        for (klass, count) in self.classes.items():\n",
    "            self.priors[klass] = count / len(data[label_name])\n",
    "\n",
    "        #\n",
    "        # now compute conditional probabilities p(h|D)\n",
    "        #\n",
    "        for (klass, features) in self.counts.items():\n",
    "            self.conditional.setdefault(klass, {})\n",
    "            for (feature, value_counts) in features.items():\n",
    "                self.conditional[klass].setdefault(feature, {})\n",
    "                for (value, count) in value_counts.items():\n",
    "                    self.conditional[klass][feature][value] = ( count / self.classes[klass])\n",
    "\n",
    "        # now compute mean and ssd\n",
    "        for (klass, features) in self.totals.items():\n",
    "            self.means.setdefault(klass, {})\n",
    "            for (feature, feature_total) in features.items():\n",
    "                self.means[klass][feature] = feature_total / self.classes[klass]\n",
    "\n",
    "        # standard deviation\n",
    "        for (klass, features) in self.means.items():\n",
    "            self.ssds.setdefault(klass, {})\n",
    "            for (feature, mean) in features.items():\n",
    "                sum_of_square_differences = 0\n",
    "                for i in range(len(data[feature])):\n",
    "                    if data[label_name][i] == klass:\n",
    "                        sum_of_square_differences += (data[feature][i] - mean)**2\n",
    "                self.ssds[klass][feature] = math.sqrt(sum_of_square_differences / \\\n",
    "                                                      (self.classes[klass] - 1))\n",
    "    \n",
    "\n",
    "    # making prediction for an unseen instance using trained NB model\n",
    "    def classify(self, instance, cat_feature_names, num_feature_names):\n",
    "        results = []\n",
    "        for (klass, prior) in self.priors.items():\n",
    "            prob = prior\n",
    "            for feature in cat_feature_names:\n",
    "                if not instance[feature] in self.conditional[klass][feature]:\n",
    "                    # we did not find any instances of this attribute value\n",
    "                    # occurring with this class so prob = 0\n",
    "                    prob = 0\n",
    "                else:\n",
    "                    prob = prob * self.conditional[klass][feature][instance[feature]]\n",
    "\n",
    "            for feature in num_feature_names:\n",
    "                mean = self.means[klass][feature]\n",
    "                ssd = self.ssds[klass][feature]\n",
    "                prob = prob * self.pdf(mean, ssd, instance[feature])\n",
    "\n",
    "            results.append((prob, klass))\n",
    "\n",
    "        # return the class with the highest probability\n",
    "        return(max(results)[1])\n",
    "\n",
    "\n",
    "    # Probability Density Function  computing P(x|y)\n",
    "    def pdf(self, mean, ssd, x):\n",
    "        ePart = math.pow(math.e, -(x-mean)**2/(2*ssd**2))\n",
    "        return (1.0 / (math.sqrt(2*math.pi)*ssd)) * ePart\n",
    "\n",
    "\n",
    "    # take a list of instances which each one is a dictionary\n",
    "    def test(self, test_data, cat_feature_names, num_feature_names):\n",
    "        predictions = []\n",
    "\n",
    "        # make a prediction for every instance\n",
    "        feature_names = list(test_data.keys())\n",
    "        length = len(test_data[ feature_names[0] ])\n",
    "        for i in range(length):\n",
    "            test_instance = { feature:test_data[feature][i] for feature in feature_names }\n",
    "\n",
    "            predictions.append(self.classify(test_instance, cat_feature_names, num_feature_names))\n",
    "\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46054ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values of a list with a new item if they exist in o_items\n",
    "def replace_items(l, o_items, n_item):\n",
    "    return [n_item if item in o_items else item for item in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ffa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610727b3",
   "metadata": {},
   "source": [
    "# breast-cancer-wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79ac95",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d364b2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785714285714285"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=10)\n",
    "#X = X.drop(columns=0)\n",
    "y = df[10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "feature_names.remove(0)\n",
    "#num_feature_names = [feature_names[0]]\n",
    "num_feature_names = []\n",
    "cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "\n",
    "classifier = NB()\n",
    "classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "\n",
    "my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9a7d7",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a2533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.9571428571428572\n",
      "fold:  2 ===> accuracy:  0.9571428571428572\n",
      "fold:  3 ===> accuracy:  0.9714285714285714\n",
      "fold:  4 ===> accuracy:  0.9642857142857143\n",
      "fold:  5 ===> accuracy:  0.9640287769784173\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.9785714285714285\n",
      "fold:  2 ===> accuracy:  0.9714285714285714\n",
      "fold:  3 ===> accuracy:  0.9857142857142858\n",
      "fold:  4 ===> accuracy:  0.9357142857142857\n",
      "fold:  5 ===> accuracy:  0.9568345323741008\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.9714285714285714\n",
      "fold:  2 ===> accuracy:  0.9642857142857143\n",
      "fold:  3 ===> accuracy:  0.9857142857142858\n",
      "fold:  4 ===> accuracy:  0.9642857142857143\n",
      "fold:  5 ===> accuracy:  0.9496402877697842\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.9428571428571428\n",
      "fold:  2 ===> accuracy:  0.9714285714285714\n",
      "fold:  3 ===> accuracy:  0.9928571428571429\n",
      "fold:  4 ===> accuracy:  0.9642857142857143\n",
      "fold:  5 ===> accuracy:  0.9640287769784173\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.9857142857142858\n",
      "fold:  2 ===> accuracy:  0.9428571428571428\n",
      "fold:  3 ===> accuracy:  0.9642857142857143\n",
      "fold:  4 ===> accuracy:  0.9785714285714285\n",
      "fold:  5 ===> accuracy:  0.9640287769784173\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.9642857142857143\n",
      "fold:  2 ===> accuracy:  0.9714285714285714\n",
      "fold:  3 ===> accuracy:  0.95\n",
      "fold:  4 ===> accuracy:  0.9642857142857143\n",
      "fold:  5 ===> accuracy:  0.9784172661870504\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.9785714285714285\n",
      "fold:  2 ===> accuracy:  0.9571428571428572\n",
      "fold:  3 ===> accuracy:  0.95\n",
      "fold:  4 ===> accuracy:  0.9642857142857143\n",
      "fold:  5 ===> accuracy:  0.9712230215827338\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.9571428571428572\n",
      "fold:  2 ===> accuracy:  0.9571428571428572\n",
      "fold:  3 ===> accuracy:  0.9714285714285714\n",
      "fold:  4 ===> accuracy:  0.9857142857142858\n",
      "fold:  5 ===> accuracy:  0.9496402877697842\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.95\n",
      "fold:  2 ===> accuracy:  0.9642857142857143\n",
      "fold:  3 ===> accuracy:  0.9857142857142858\n",
      "fold:  4 ===> accuracy:  0.95\n",
      "fold:  5 ===> accuracy:  0.9856115107913669\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.9142857142857143\n",
      "fold:  2 ===> accuracy:  0.9357142857142857\n",
      "fold:  3 ===> accuracy:  0.9714285714285714\n",
      "fold:  4 ===> accuracy:  0.9857142857142858\n",
      "fold:  5 ===> accuracy:  0.9856115107913669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "\n",
    "target = df[10]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=10)\n",
    "        y = train[10]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=10)\n",
    "        y_test = test[10]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        feature_names.remove(0)\n",
    "        num_feature_names = []\n",
    "        cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "                \n",
    "        classifier = NB()\n",
    "        classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "        my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3718c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc58b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.015832749333826498\n",
      "Mean:  0.9649527235354574\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f786925",
   "metadata": {},
   "source": [
    "# car dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624fdc06",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61372ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353765323992994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./car.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=6)\n",
    "y = df[6]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "num_feature_names = []\n",
    "cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "\n",
    "classifier = NB()\n",
    "classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3db08",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6a374e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.8641618497109826\n",
      "fold:  2 ===> accuracy:  0.8352601156069365\n",
      "fold:  3 ===> accuracy:  0.8583815028901735\n",
      "fold:  4 ===> accuracy:  0.8724637681159421\n",
      "fold:  5 ===> accuracy:  0.863768115942029\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.8265895953757225\n",
      "fold:  2 ===> accuracy:  0.8497109826589595\n",
      "fold:  3 ===> accuracy:  0.8497109826589595\n",
      "fold:  4 ===> accuracy:  0.8492753623188406\n",
      "fold:  5 ===> accuracy:  0.8608695652173913\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.8236994219653179\n",
      "fold:  2 ===> accuracy:  0.861271676300578\n",
      "fold:  3 ===> accuracy:  0.8786127167630058\n",
      "fold:  4 ===> accuracy:  0.863768115942029\n",
      "fold:  5 ===> accuracy:  0.8492753623188406\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.9017341040462428\n",
      "fold:  2 ===> accuracy:  0.8352601156069365\n",
      "fold:  3 ===> accuracy:  0.8526011560693642\n",
      "fold:  4 ===> accuracy:  0.8753623188405797\n",
      "fold:  5 ===> accuracy:  0.7942028985507247\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.869942196531792\n",
      "fold:  2 ===> accuracy:  0.8294797687861272\n",
      "fold:  3 ===> accuracy:  0.8670520231213873\n",
      "fold:  4 ===> accuracy:  0.8898550724637682\n",
      "fold:  5 ===> accuracy:  0.8405797101449275\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.884393063583815\n",
      "fold:  2 ===> accuracy:  0.8439306358381503\n",
      "fold:  3 ===> accuracy:  0.8554913294797688\n",
      "fold:  4 ===> accuracy:  0.8405797101449275\n",
      "fold:  5 ===> accuracy:  0.8956521739130435\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.838150289017341\n",
      "fold:  2 ===> accuracy:  0.8728323699421965\n",
      "fold:  3 ===> accuracy:  0.846820809248555\n",
      "fold:  4 ===> accuracy:  0.8782608695652174\n",
      "fold:  5 ===> accuracy:  0.855072463768116\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.8265895953757225\n",
      "fold:  2 ===> accuracy:  0.838150289017341\n",
      "fold:  3 ===> accuracy:  0.8583815028901735\n",
      "fold:  4 ===> accuracy:  0.8985507246376812\n",
      "fold:  5 ===> accuracy:  0.8405797101449275\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.8439306358381503\n",
      "fold:  2 ===> accuracy:  0.9132947976878613\n",
      "fold:  3 ===> accuracy:  0.8439306358381503\n",
      "fold:  4 ===> accuracy:  0.8173913043478261\n",
      "fold:  5 ===> accuracy:  0.863768115942029\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.869942196531792\n",
      "fold:  2 ===> accuracy:  0.869942196531792\n",
      "fold:  3 ===> accuracy:  0.8410404624277457\n",
      "fold:  4 ===> accuracy:  0.8289855072463768\n",
      "fold:  5 ===> accuracy:  0.8608695652173913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "df = pd.read_csv('./car.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "target = df[6]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=6)\n",
    "        y = train[6]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=6)\n",
    "        y_test = test[6]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        num_feature_names = []\n",
    "        cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "        \n",
    "        classifier = NB()\n",
    "        classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "        my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "        \n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1fb00ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "875b3a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.023183805279741124\n",
      "Mean:  0.855788389042473\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084c53d",
   "metadata": {},
   "source": [
    "# mushroom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e6f45",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c58c1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977620290936218"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "X = X.drop(columns=11)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "num_feature_names = []\n",
    "cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "\n",
    "\n",
    "classifier = NB()\n",
    "classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6cae3",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0deb9d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.9956923076923077\n",
      "fold:  2 ===> accuracy:  0.9963076923076923\n",
      "fold:  3 ===> accuracy:  0.9981538461538462\n",
      "fold:  4 ===> accuracy:  0.9981538461538462\n",
      "fold:  5 ===> accuracy:  0.9975369458128078\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.9950769230769231\n",
      "fold:  2 ===> accuracy:  0.9969230769230769\n",
      "fold:  3 ===> accuracy:  0.9981538461538462\n",
      "fold:  4 ===> accuracy:  0.9975384615384615\n",
      "fold:  5 ===> accuracy:  0.9969211822660099\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.9987692307692307\n",
      "fold:  2 ===> accuracy:  0.9969230769230769\n",
      "fold:  3 ===> accuracy:  0.9969230769230769\n",
      "fold:  4 ===> accuracy:  0.9956923076923077\n",
      "fold:  5 ===> accuracy:  0.9969211822660099\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.9981538461538462\n",
      "fold:  2 ===> accuracy:  0.9969230769230769\n",
      "fold:  3 ===> accuracy:  0.9981538461538462\n",
      "fold:  4 ===> accuracy:  0.9938461538461538\n",
      "fold:  5 ===> accuracy:  0.9975369458128078\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.9932307692307693\n",
      "fold:  2 ===> accuracy:  0.9981538461538462\n",
      "fold:  3 ===> accuracy:  0.9981538461538462\n",
      "fold:  4 ===> accuracy:  0.9981538461538462\n",
      "fold:  5 ===> accuracy:  0.9950738916256158\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.9963076923076923\n",
      "fold:  2 ===> accuracy:  0.9969230769230769\n",
      "fold:  3 ===> accuracy:  0.9975384615384615\n",
      "fold:  4 ===> accuracy:  0.9956923076923077\n",
      "fold:  5 ===> accuracy:  0.9987684729064039\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.9987692307692307\n",
      "fold:  2 ===> accuracy:  0.992\n",
      "fold:  3 ===> accuracy:  0.9975384615384615\n",
      "fold:  4 ===> accuracy:  0.9993846153846154\n",
      "fold:  5 ===> accuracy:  0.9956896551724138\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.9963076923076923\n",
      "fold:  2 ===> accuracy:  0.9981538461538462\n",
      "fold:  3 ===> accuracy:  0.9969230769230769\n",
      "fold:  4 ===> accuracy:  0.9969230769230769\n",
      "fold:  5 ===> accuracy:  0.9969211822660099\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.9950769230769231\n",
      "fold:  2 ===> accuracy:  0.9975384615384615\n",
      "fold:  3 ===> accuracy:  0.9981538461538462\n",
      "fold:  4 ===> accuracy:  0.9950769230769231\n",
      "fold:  5 ===> accuracy:  0.9981527093596059\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.9963076923076923\n",
      "fold:  2 ===> accuracy:  0.9956923076923077\n",
      "fold:  3 ===> accuracy:  0.9956923076923077\n",
      "fold:  4 ===> accuracy:  0.9981538461538462\n",
      "fold:  5 ===> accuracy:  0.9981527093596059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "target = df[0]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=0)\n",
    "        X = X.drop(columns=11)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=0)\n",
    "        X_test = X_test.drop(columns=11)\n",
    "        y_test = test[0]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        num_feature_names = []\n",
    "        cat_feature_names = [i for i in feature_names if i not in num_feature_names]\n",
    "\n",
    "        \n",
    "        classifier = NB()\n",
    "        classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "        my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d449e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb40887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0014969148982159944\n",
      "Mean:  0.9968981129215612\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de48215",
   "metadata": {},
   "source": [
    "# ecoli dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f1ff7",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88e527ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=8)\n",
    "y = df[8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_demo[8] = replace_items(d_demo[8],'imS','im')\n",
    "d_demo[8] = replace_items(d_demo[8],'imL','im')\n",
    "d_demo[8] = replace_items(d_demo[8],'omL','mL')\n",
    "\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "y_test = replace_items(y_test,'imS','im')\n",
    "y_test = replace_items(y_test,'imL','im')\n",
    "y_test = replace_items(y_test,'omL','mL')\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "num_feature_names = [ feature_names[i] for i in [1,2,5,6,7] ]\n",
    "cat_feature_names = [ feature_names[i] for i in [3,4] ]\n",
    "\n",
    "\n",
    "classifier = NB()\n",
    "classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538d156",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e0aa1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.9117647058823529\n",
      "fold:  2 ===> accuracy:  0.8507462686567164\n",
      "fold:  3 ===> accuracy:  0.8059701492537313\n",
      "fold:  4 ===> accuracy:  0.8656716417910447\n",
      "fold:  5 ===> accuracy:  0.8955223880597015\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.8088235294117647\n",
      "fold:  2 ===> accuracy:  0.8656716417910447\n",
      "fold:  3 ===> accuracy:  0.8656716417910447\n",
      "fold:  4 ===> accuracy:  0.9104477611940298\n",
      "fold:  5 ===> accuracy:  0.8507462686567164\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.8676470588235294\n",
      "fold:  2 ===> accuracy:  0.8656716417910447\n",
      "fold:  3 ===> accuracy:  0.9104477611940298\n",
      "fold:  4 ===> accuracy:  0.8059701492537313\n",
      "fold:  5 ===> accuracy:  0.8059701492537313\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.8823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 ===> accuracy:  0.9104477611940298\n",
      "fold:  3 ===> accuracy:  0.8656716417910447\n",
      "fold:  4 ===> accuracy:  0.835820895522388\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.9705882352941176\n",
      "fold:  2 ===> accuracy:  0.8507462686567164\n",
      "fold:  3 ===> accuracy:  0.8059701492537313\n",
      "fold:  4 ===> accuracy:  0.8208955223880597\n",
      "fold:  5 ===> accuracy:  0.8507462686567164\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.8235294117647058\n",
      "fold:  2 ===> accuracy:  0.8656716417910447\n",
      "fold:  3 ===> accuracy:  0.8656716417910447\n",
      "fold:  4 ===> accuracy:  0.8059701492537313\n",
      "fold:  5 ===> accuracy:  0.8805970149253731\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.8656716417910447\n",
      "fold:  3 ===> accuracy:  0.8507462686567164\n",
      "fold:  4 ===> accuracy:  0.8507462686567164\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n",
      "================Run 7================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.8676470588235294\n",
      "fold:  2 ===> accuracy:  0.8805970149253731\n",
      "fold:  3 ===> accuracy:  0.8805970149253731\n",
      "fold:  4 ===> accuracy:  0.7761194029850746\n",
      "fold:  5 ===> accuracy:  0.9552238805970149\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.8235294117647058\n",
      "fold:  2 ===> accuracy:  0.835820895522388\n",
      "fold:  3 ===> accuracy:  0.835820895522388\n",
      "fold:  4 ===> accuracy:  0.835820895522388\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.8970588235294118\n",
      "fold:  2 ===> accuracy:  0.9104477611940298\n",
      "fold:  3 ===> accuracy:  0.8805970149253731\n",
      "fold:  4 ===> accuracy:  0.7761194029850746\n",
      "fold:  5 ===> accuracy:  0.8656716417910447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "target = df[8]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=8)\n",
    "        y = train[8]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        d_demo[8] = replace_items(d_demo[8],'imS','im')\n",
    "        d_demo[8] = replace_items(d_demo[8],'imL','im')\n",
    "        d_demo[8] = replace_items(d_demo[8],'omL','mL')\n",
    "        \n",
    "        X_test = test.drop(columns=8)\n",
    "        y_test = test[8]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "        y_test = replace_items(y_test,'imS','im')\n",
    "        y_test = replace_items(y_test,'imL','im')\n",
    "        y_test = replace_items(y_test,'omL','mL')\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        num_feature_names = [ feature_names[i] for i in [1,2,5,6,7] ]\n",
    "        cat_feature_names = [ feature_names[i] for i in [3,4] ]\n",
    "        \n",
    "        \n",
    "        classifier = NB()\n",
    "        classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "        my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59b79df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d24c79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.040201892457361305\n",
      "Mean:  0.8600746268656716\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26ceef",
   "metadata": {},
   "source": [
    "# letter-recognition dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220c6b3",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dab9d32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "feature_names.remove(label_name)\n",
    "num_feature_names = []\n",
    "cat_feature_names = feature_names\n",
    "\n",
    "classifier = NB()\n",
    "classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6048b",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e7d1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.7465\n",
      "fold:  2 ===> accuracy:  0.755\n",
      "fold:  3 ===> accuracy:  0.7375\n",
      "fold:  4 ===> accuracy:  0.7505\n",
      "fold:  5 ===> accuracy:  0.74575\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.7505\n",
      "fold:  2 ===> accuracy:  0.745\n",
      "fold:  3 ===> accuracy:  0.7455\n",
      "fold:  4 ===> accuracy:  0.75075\n",
      "fold:  5 ===> accuracy:  0.7495\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.749\n",
      "fold:  2 ===> accuracy:  0.75825\n",
      "fold:  3 ===> accuracy:  0.74175\n",
      "fold:  4 ===> accuracy:  0.75175\n",
      "fold:  5 ===> accuracy:  0.73675\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.74725\n",
      "fold:  2 ===> accuracy:  0.74775\n",
      "fold:  3 ===> accuracy:  0.75175\n",
      "fold:  4 ===> accuracy:  0.73975\n",
      "fold:  5 ===> accuracy:  0.74525\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.7495\n",
      "fold:  2 ===> accuracy:  0.74675\n",
      "fold:  3 ===> accuracy:  0.746\n",
      "fold:  4 ===> accuracy:  0.7515\n",
      "fold:  5 ===> accuracy:  0.74225\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.733\n",
      "fold:  2 ===> accuracy:  0.74875\n",
      "fold:  3 ===> accuracy:  0.75675\n",
      "fold:  4 ===> accuracy:  0.74725\n",
      "fold:  5 ===> accuracy:  0.7525\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.763\n",
      "fold:  2 ===> accuracy:  0.7525\n",
      "fold:  3 ===> accuracy:  0.73475\n",
      "fold:  4 ===> accuracy:  0.74625\n",
      "fold:  5 ===> accuracy:  0.745\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.7465\n",
      "fold:  2 ===> accuracy:  0.746\n",
      "fold:  3 ===> accuracy:  0.747\n",
      "fold:  4 ===> accuracy:  0.753\n",
      "fold:  5 ===> accuracy:  0.74575\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.74125\n",
      "fold:  2 ===> accuracy:  0.754\n",
      "fold:  3 ===> accuracy:  0.74525\n",
      "fold:  4 ===> accuracy:  0.74975\n",
      "fold:  5 ===> accuracy:  0.74275\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.746\n",
      "fold:  2 ===> accuracy:  0.737\n",
      "fold:  3 ===> accuracy:  0.749\n",
      "fold:  4 ===> accuracy:  0.74525\n",
      "fold:  5 ===> accuracy:  0.7575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "target = df[0]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=0)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=0)\n",
    "        y_test = test[0]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        feature_names.remove(label_name)\n",
    "        num_feature_names = []\n",
    "        cat_feature_names = feature_names\n",
    "\n",
    "        classifier = NB()\n",
    "        classifier.train(d_demo, cat_feature_names, num_feature_names, label_name)\n",
    "        my_pred = classifier.test(d_test, cat_feature_names, num_feature_names)\n",
    "        accuracy_score(y_test, my_pred)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26e5e06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1b36cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.005974221834733976\n",
      "Mean:  0.74735\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3d3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
