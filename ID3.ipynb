{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "818c2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "\n",
    "class ID3:\n",
    "    def __init__(self):\n",
    "        self.mins_steps = {}\n",
    "        self.tree = {}\n",
    "        self.majority_class = 'hi_classssss'\n",
    "        \n",
    "        \n",
    "    # return records if feature_name == value \n",
    "    def data_filter(self, data, feature_name, value):\n",
    "        new_data = {}\n",
    "        for key in list(data.keys()):\n",
    "            new_data[key] = []\n",
    "\n",
    "        for i in range(len(data[feature_name])):\n",
    "            if data[feature_name][i] == value:\n",
    "                for key in data.keys():\n",
    "                    new_data[key].append(data[key][i])\n",
    "\n",
    "        return new_data\n",
    "\n",
    "\n",
    "\n",
    "    # Find the entropy of the given feature\n",
    "    def entropy(self, feature_column):\n",
    "        # find the frequency of each unique value for the given feature\n",
    "        counts = [feature_column.count(i) for i in list(set(feature_column))]\n",
    "\n",
    "        total_entropy = 0\n",
    "\n",
    "        for count in counts:\n",
    "            probability = count/sum(counts)\n",
    "            #total_entropy += (-probability * log2(probability))\n",
    "            total_entropy -= probability * log2(probability)\n",
    "\n",
    "        return total_entropy\n",
    "\n",
    "\n",
    "    # Informatino Gain = Entropy(parent) - [average entropy(children)]  \n",
    "    def information_gain(self, data, feature_name, label_name):\n",
    "        # find the entropy of given data\n",
    "        parent_entropy = self.entropy(data[label_name])\n",
    "\n",
    "        # find unique values and their frequency for the attribute to be split\n",
    "        freqs = dict( (i, data[feature_name].count(i)) for i in \n",
    "                 list(set( data[feature_name] )) )\n",
    "\n",
    "        # calculate weighted entropy of all subsets\n",
    "        total_weighted_entropy = 0\n",
    "\n",
    "        for v, freq in freqs.items():\n",
    "            subset_probability = freq/sum(freqs.values())\n",
    "\n",
    "            subset_entropy = self.entropy(self.data_filter(data, feature_name, v)[label_name])\n",
    "            total_weighted_entropy += (subset_probability*subset_entropy)\n",
    "\n",
    "\n",
    "        # calculate information gain\n",
    "        information_gain = parent_entropy - total_weighted_entropy\n",
    "\n",
    "        return information_gain\n",
    "\n",
    "\n",
    "    # creating the decision tree\n",
    "    def train(self, data, label_name, discrete_attributes):\n",
    "        feature_names = list(data.keys())\n",
    "        feature_names.remove(label_name)\n",
    "\n",
    "        # determine majority class\n",
    "        class_freqs = dict( (i, data[label_name].count(i)) for i in \\\n",
    "                             list(set( data[label_name] )) )\n",
    "        self.majority_class = sorted(class_freqs, key=lambda x : class_freqs[x], reverse=True)[0]\n",
    "        \n",
    "        for attr in discrete_attributes:\n",
    "            data[attr], self.mins_steps[attr] = self.discretize_list(data[attr])\n",
    "        \n",
    "        self.tree = self.build_tree(data, data, feature_names, label_name, \\\n",
    "                                    self.majority_class, self.majority_class)\n",
    "        \n",
    "        \n",
    "    # creating the decision tree\n",
    "    def build_tree(self, data, original_data, feature_names, label_name, \\\n",
    "                      majority_class, parent_node_class=None):\n",
    "        # if data set contains no features to train with, return parent node class\n",
    "        if len(feature_names) == 0:\n",
    "            #print(\"1:\", parent_node_class)\n",
    "            return parent_node_class\n",
    "        # if subset is empty, ie. no samples, return majority class of original data\n",
    "        elif len(data[label_name]) == 0:\n",
    "            #print(\"2:\", majority_class)\n",
    "            return majority_class\n",
    "        # if data is pure, return the majority class of subset\n",
    "        elif len(list(set( data[label_name] ))) <= 1:\n",
    "            #print(\"3:\", '3'+list(set( data[label_name] ))[0])\n",
    "            return list(set( data[label_name] ))[0]\n",
    "        # if none of the above are true, construct a branch:\n",
    "        else:\n",
    "            # determine parent node class of current branch\n",
    "            class_freqs = dict( (i, data[label_name].count(i)) for i in \\\n",
    "                         list(set( data[label_name] )) )\n",
    "            parent_node_class = sorted(class_freqs, key=lambda x : class_freqs[x], reverse=True)[0]\n",
    "\n",
    "            # determine information gain values for each feature\n",
    "            # choose feature which best splits the data, ie. highest value\n",
    "            gains = dict( (feature, self.information_gain(data, feature, label_name)) for \\\n",
    "                               feature in feature_names ) \n",
    "            best_feature = sorted(gains, key=lambda x : gains[x], reverse=True)[0]\n",
    "\n",
    "\n",
    "            # create tree structure, empty at first\n",
    "            tree = {best_feature: {}}\n",
    "\n",
    "            # remove best feature from available features, it will become the parent node\n",
    "            #feature_names.remove(best_feature)\n",
    "            feature_names = [i for i in feature_names if i != best_feature]\n",
    "\n",
    "\n",
    "            # create nodes under parent node\n",
    "            for value in list(set( data[best_feature] )): #or original_data[best_feature]\n",
    "                new_branch_data = self.data_filter(data, best_feature, value)\n",
    "\n",
    "                # call the algorithm recursively\n",
    "                new_branch = self.build_tree(new_branch_data, original_data, feature_names, \\\n",
    "                                           label_name, majority_class, parent_node_class)\n",
    "\n",
    "                # add subtree to original tree\n",
    "                tree[best_feature][value] = new_branch\n",
    "\n",
    "            return tree\n",
    "    \n",
    "    \n",
    "    # making prediction for an unseen instance using created tree\n",
    "    def classify(self, instance, current_tree):\n",
    "        # map instance data to tree\n",
    "        for attribute in list(instance.keys()):\n",
    "            # check if feature exists in tree\n",
    "            if attribute in list(current_tree.keys()):\n",
    "                try:\n",
    "                    result = current_tree[attribute][instance[attribute]]\n",
    "                except:\n",
    "                    return self.majority_class\n",
    "\n",
    "                result = current_tree[attribute][instance[attribute]]\n",
    "\n",
    "                # if more attributes exist within result, recursively find best result\n",
    "                if isinstance(result, dict):\n",
    "                    return self.classify(instance, result)\n",
    "                else:\n",
    "                    return result\n",
    "            \n",
    "\n",
    "    # take a list of instances which each one is a dictionary\n",
    "    def test(self, test_data, discrete_attributes):\n",
    "        predictions = []\n",
    "\n",
    "        # make a prediction for every instance\n",
    "        feature_names = list(test_data.keys())\n",
    "        length = len(test_data[ feature_names[0] ])\n",
    "        for i in range(length):\n",
    "            test_instance = { feature:test_data[feature][i] for feature in feature_names }\n",
    "\n",
    "            for attr in discrete_attributes:\n",
    "                test_instance[attr] = self.discretize_value(self.mins_steps[attr][0], \\\n",
    "                                                            self.mins_steps[attr][1], \\\n",
    "                                                            test_instance[attr])\n",
    "            predictions.append(self.classify(test_instance, self.tree))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def discretize_list(self, l):\n",
    "        min_value = min(l)\n",
    "        step = ( max(l) - min(l) ) / 10\n",
    "        ranges = []\n",
    "        for i in range(10):\n",
    "            ranges.append(min_value + (i * step))\n",
    "\n",
    "        new_l = []\n",
    "        for value in l:\n",
    "            new_value = 10\n",
    "            for index_range in zip(range(len(ranges)), ranges):\n",
    "                if value < index_range[1]:\n",
    "                    new_value = index_range[0]\n",
    "                    break\n",
    "            new_l.append(new_value)\n",
    "        return new_l, (min_value, step)\n",
    "\n",
    "    def discretize_value(self, min_value, step, value):\n",
    "        ranges = []\n",
    "        for i in range(10):\n",
    "            ranges.append(min_value + (i * step))\n",
    "\n",
    "        new_value = 10\n",
    "        for index_range in zip(range(len(ranges)), ranges):\n",
    "            if value < index_range[1]:\n",
    "                new_value = index_range[0]\n",
    "                return new_value\n",
    "        return new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16ffa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the below libraries only to read the data from files.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610727b3",
   "metadata": {},
   "source": [
    "# breast-cancer-wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e48b3e",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d364b2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7168141592920354"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=10)\n",
    "y = df[10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "\n",
    "classifier = ID3()\n",
    "classifier.train(d_demo, label_name, discrete_attributes)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150aff8",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e038cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "\n",
    "target = df[10]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=10)\n",
    "        y = train[10]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=10)\n",
    "        y_test = test[10]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "        \n",
    "        classifier = ID3()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37c0b8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b932d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0024110947709128448\n",
      "Mean:  0.6500751395448691\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f786925",
   "metadata": {},
   "source": [
    "# car dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84fcea",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61372ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054290718038529"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./car.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=6)\n",
    "y = df[6]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = ID3()\n",
    "classifier.train(d_demo, label_name, discrete_attributes)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fed3f",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "476da7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.8959537572254336\n",
      "fold:  2 ===> accuracy:  0.9219653179190751\n",
      "fold:  3 ===> accuracy:  0.869942196531792\n",
      "fold:  4 ===> accuracy:  0.8985507246376812\n",
      "fold:  5 ===> accuracy:  0.8898550724637682\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.9161849710982659\n",
      "fold:  2 ===> accuracy:  0.9104046242774566\n",
      "fold:  3 ===> accuracy:  0.8670520231213873\n",
      "fold:  4 ===> accuracy:  0.8753623188405797\n",
      "fold:  5 ===> accuracy:  0.8927536231884058\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.884393063583815\n",
      "fold:  2 ===> accuracy:  0.9190751445086706\n",
      "fold:  3 ===> accuracy:  0.8728323699421965\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.8985507246376812\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.884393063583815\n",
      "fold:  2 ===> accuracy:  0.9017341040462428\n",
      "fold:  3 ===> accuracy:  0.9046242774566474\n",
      "fold:  4 ===> accuracy:  0.8869565217391304\n",
      "fold:  5 ===> accuracy:  0.8927536231884058\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.8988439306358381\n",
      "fold:  2 ===> accuracy:  0.884393063583815\n",
      "fold:  3 ===> accuracy:  0.869942196531792\n",
      "fold:  4 ===> accuracy:  0.881159420289855\n",
      "fold:  5 ===> accuracy:  0.8724637681159421\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.9017341040462428\n",
      "fold:  2 ===> accuracy:  0.8872832369942196\n",
      "fold:  3 ===> accuracy:  0.9017341040462428\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.9043478260869565\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.9161849710982659\n",
      "fold:  2 ===> accuracy:  0.8930635838150289\n",
      "fold:  3 ===> accuracy:  0.8815028901734104\n",
      "fold:  4 ===> accuracy:  0.8695652173913043\n",
      "fold:  5 ===> accuracy:  0.927536231884058\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.9075144508670521\n",
      "fold:  2 ===> accuracy:  0.8872832369942196\n",
      "fold:  3 ===> accuracy:  0.9104046242774566\n",
      "fold:  4 ===> accuracy:  0.8956521739130435\n",
      "fold:  5 ===> accuracy:  0.9072463768115943\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.8959537572254336\n",
      "fold:  2 ===> accuracy:  0.884393063583815\n",
      "fold:  3 ===> accuracy:  0.8959537572254336\n",
      "fold:  4 ===> accuracy:  0.863768115942029\n",
      "fold:  5 ===> accuracy:  0.9246376811594202\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.8901734104046243\n",
      "fold:  2 ===> accuracy:  0.9075144508670521\n",
      "fold:  3 ===> accuracy:  0.884393063583815\n",
      "fold:  4 ===> accuracy:  0.8898550724637682\n",
      "fold:  5 ===> accuracy:  0.8956521739130435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./car.data', header=None)\n",
    "target = df[6]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=6)\n",
    "        y = train[6]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=6)\n",
    "        y_test = test[6]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "        \n",
    "        classifier = ID3()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb048fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22f6353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.015420059789235005\n",
      "Mean:  0.8939798944458407\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084c53d",
   "metadata": {},
   "source": [
    "# mushroom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92768a",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c58c1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "del d_demo[11]\n",
    "del d_demo[16]\n",
    "del d_test[11]\n",
    "del d_test[16]\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = ID3()\n",
    "classifier.train(d_demo, label_name, discrete_attributes)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a903e6e",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "895afe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "target = df[0]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=0)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "\n",
    "        X_test = test.drop(columns=0)\n",
    "        y_test = test[0]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "        \n",
    "        del d_demo[11]\n",
    "        del d_demo[16]\n",
    "        del d_test[11]\n",
    "        del d_test[16]\n",
    "        \n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "\n",
    "        classifier = ID3()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76cca02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d8f88e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0\n",
      "Mean:  1.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de48215",
   "metadata": {},
   "source": [
    "# ecoli dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531fa7a",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ca733df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576576576576577"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=8)\n",
    "y = df[8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "del d_demo[0]\n",
    "del d_test[0]\n",
    "discrete_attributes = [1, 2, 5, 6, 7]\n",
    "\n",
    "classifier = ID3()\n",
    "classifier.train(d_demo, label_name, discrete_attributes)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a9383",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "f74a6328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cp', 'im', 'imS', 'imL', 'imU', 'om', 'omL', 'pp'], dtype=object)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[8].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9013c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.6323529411764706\n",
      "fold:  2 ===> accuracy:  0.5970149253731343\n",
      "fold:  3 ===> accuracy:  0.7014925373134329\n",
      "fold:  4 ===> accuracy:  0.6716417910447762\n",
      "fold:  5 ===> accuracy:  0.6268656716417911\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.6617647058823529\n",
      "fold:  2 ===> accuracy:  0.582089552238806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 ===> accuracy:  0.6716417910447762\n",
      "fold:  4 ===> accuracy:  0.6865671641791045\n",
      "fold:  5 ===> accuracy:  0.7164179104477612\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.6323529411764706\n",
      "fold:  2 ===> accuracy:  0.6865671641791045\n",
      "fold:  3 ===> accuracy:  0.6268656716417911\n",
      "fold:  4 ===> accuracy:  0.6119402985074627\n",
      "fold:  5 ===> accuracy:  0.6417910447761194\n",
      "================Run 3================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.7058823529411765\n",
      "fold:  2 ===> accuracy:  0.5074626865671642\n",
      "fold:  3 ===> accuracy:  0.6716417910447762\n",
      "fold:  4 ===> accuracy:  0.6716417910447762\n",
      "fold:  5 ===> accuracy:  0.6119402985074627\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.6764705882352942\n",
      "fold:  2 ===> accuracy:  0.6268656716417911\n",
      "fold:  3 ===> accuracy:  0.7014925373134329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 ===> accuracy:  0.5671641791044776\n",
      "fold:  5 ===> accuracy:  0.746268656716418\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.6617647058823529\n",
      "fold:  2 ===> accuracy:  0.7164179104477612\n",
      "fold:  3 ===> accuracy:  0.5970149253731343\n",
      "fold:  4 ===> accuracy:  0.5522388059701493\n",
      "fold:  5 ===> accuracy:  0.6716417910447762\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.6323529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 ===> accuracy:  0.6865671641791045\n",
      "fold:  3 ===> accuracy:  0.6865671641791045\n",
      "fold:  4 ===> accuracy:  0.6865671641791045\n",
      "fold:  5 ===> accuracy:  0.582089552238806\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.6617647058823529\n",
      "fold:  2 ===> accuracy:  0.6865671641791045\n",
      "fold:  3 ===> accuracy:  0.6567164179104478\n",
      "fold:  4 ===> accuracy:  0.5970149253731343\n",
      "fold:  5 ===> accuracy:  0.6567164179104478\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.6029411764705882\n",
      "fold:  2 ===> accuracy:  0.6268656716417911\n",
      "fold:  3 ===> accuracy:  0.5970149253731343\n",
      "fold:  4 ===> accuracy:  0.7313432835820896\n",
      "fold:  5 ===> accuracy:  0.6268656716417911\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.6617647058823529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 ===> accuracy:  0.6865671641791045\n",
      "fold:  3 ===> accuracy:  0.582089552238806\n",
      "fold:  4 ===> accuracy:  0.7761194029850746\n",
      "fold:  5 ===> accuracy:  0.582089552238806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "target = df[8]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=8)\n",
    "        y = train[8]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=8)\n",
    "        y_test = test[8]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "        \n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        del d_demo[0]\n",
    "        del d_test[0]\n",
    "        discrete_attributes = [1, 2, 5, 6, 7]\n",
    "\n",
    "        classifier = ID3()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "390fb3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b6d32936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.052917967626446995\n",
      "Mean:  0.6487971905179982\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e090228",
   "metadata": {},
   "source": [
    "# letter-recognition dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b4b7d",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a4199d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133333333333334"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = ID3()\n",
    "classifier.train(d_demo, label_name, discrete_attributes)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7487ff",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9a31e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.72625\n",
      "fold:  2 ===> accuracy:  0.7285\n",
      "fold:  3 ===> accuracy:  0.72525\n",
      "fold:  4 ===> accuracy:  0.72675\n",
      "fold:  5 ===> accuracy:  0.72675\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.731\n",
      "fold:  2 ===> accuracy:  0.7215\n",
      "fold:  3 ===> accuracy:  0.739\n",
      "fold:  4 ===> accuracy:  0.73175\n",
      "fold:  5 ===> accuracy:  0.71875\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.7275\n",
      "fold:  2 ===> accuracy:  0.7335\n",
      "fold:  3 ===> accuracy:  0.72875\n",
      "fold:  4 ===> accuracy:  0.724\n",
      "fold:  5 ===> accuracy:  0.734\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.71875\n",
      "fold:  2 ===> accuracy:  0.73175\n",
      "fold:  3 ===> accuracy:  0.73275\n",
      "fold:  4 ===> accuracy:  0.733\n",
      "fold:  5 ===> accuracy:  0.729\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.7285\n",
      "fold:  2 ===> accuracy:  0.732\n",
      "fold:  3 ===> accuracy:  0.72825\n",
      "fold:  4 ===> accuracy:  0.72225\n",
      "fold:  5 ===> accuracy:  0.7365\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.7265\n",
      "fold:  2 ===> accuracy:  0.73\n",
      "fold:  3 ===> accuracy:  0.72775\n",
      "fold:  4 ===> accuracy:  0.72725\n",
      "fold:  5 ===> accuracy:  0.729\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.72625\n",
      "fold:  2 ===> accuracy:  0.72925\n",
      "fold:  3 ===> accuracy:  0.73725\n",
      "fold:  4 ===> accuracy:  0.728\n",
      "fold:  5 ===> accuracy:  0.71675\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.71425\n",
      "fold:  2 ===> accuracy:  0.71975\n",
      "fold:  3 ===> accuracy:  0.73475\n",
      "fold:  4 ===> accuracy:  0.7335\n",
      "fold:  5 ===> accuracy:  0.72625\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.72775\n",
      "fold:  2 ===> accuracy:  0.729\n",
      "fold:  3 ===> accuracy:  0.7275\n",
      "fold:  4 ===> accuracy:  0.7455\n",
      "fold:  5 ===> accuracy:  0.7215\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.732\n",
      "fold:  2 ===> accuracy:  0.73675\n",
      "fold:  3 ===> accuracy:  0.71375\n",
      "fold:  4 ===> accuracy:  0.72475\n",
      "fold:  5 ===> accuracy:  0.725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "target = df[0]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=0)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=0)\n",
    "        y_test = test[0]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "        \n",
    "        classifier = ID3()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "d0787726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "07d609ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0065344456223796685\n",
      "Mean:  0.7282\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e2926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
