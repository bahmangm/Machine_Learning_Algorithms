{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ffa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the below libraries only to read the data from files.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818c2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "class RF:\n",
    "    def __init__(self):\n",
    "        self.mins_steps = {}\n",
    "        #self.tree = {}\n",
    "        self.trees = []\n",
    "        self.RF_majority_class = 'hi_classssss'\n",
    "        \n",
    "        \n",
    "    # return records if feature_name == value \n",
    "    def data_filter(self, data, feature_name, value):\n",
    "        new_data = {}\n",
    "        for key in list(data.keys()):\n",
    "            new_data[key] = []\n",
    "\n",
    "        for i in range(len(data[feature_name])):\n",
    "            if data[feature_name][i] == value:\n",
    "                for key in data.keys():\n",
    "                    new_data[key].append(data[key][i])\n",
    "\n",
    "        return new_data\n",
    "\n",
    "\n",
    "    # Find the entropy of the given feature\n",
    "    def entropy(self, feature_column):\n",
    "        # find the frequency of each unique value for the given feature\n",
    "        counts = [feature_column.count(i) for i in list(set(feature_column))]\n",
    "\n",
    "        total_entropy = 0\n",
    "\n",
    "        for count in counts:\n",
    "            probability = count/sum(counts)\n",
    "            #total_entropy += (-probability * log2(probability))\n",
    "            total_entropy -= probability * log2(probability)\n",
    "\n",
    "        return total_entropy\n",
    "\n",
    "\n",
    "    # Informatino Gain = Entropy(parent) - [average entropy(children)]  \n",
    "    def information_gain(self, data, feature_name, label_name):\n",
    "        # find the entropy of given data\n",
    "        parent_entropy = self.entropy(data[label_name])\n",
    "\n",
    "        # find unique values and their frequency for the attribute to be split\n",
    "        freqs = dict( (i, data[feature_name].count(i)) for i in \n",
    "                 list(set( data[feature_name] )) )\n",
    "\n",
    "        # calculate weighted entropy of all subsets\n",
    "        total_weighted_entropy = 0\n",
    "        for v, freq in freqs.items():\n",
    "            subset_probability = freq/sum(freqs.values())\n",
    "\n",
    "            subset_entropy = self.entropy(self.data_filter(data, feature_name, v)[label_name])\n",
    "            total_weighted_entropy += (subset_probability*subset_entropy)\n",
    "\n",
    "        # calculate information gain\n",
    "        information_gain = parent_entropy - total_weighted_entropy\n",
    "        return information_gain\n",
    "    \n",
    "    \n",
    "    # creating the random forest\n",
    "    def train(self, data, label_name, discrete_attributes, size = 5):\n",
    "        \n",
    "        feature_names = list(data.keys())\n",
    "        feature_names.remove(label_name)\n",
    "\n",
    "        majority_classes = []\n",
    "        for i in range(size):\n",
    "            sample_data = self.sampling(data)\n",
    "            # determine majority class\n",
    "            class_freqs = dict( (i, sample_data[label_name].count(i)) for i in \\\n",
    "                                 list(set( sample_data[label_name] )) )\n",
    "            majority_class = sorted(class_freqs, key=lambda x : class_freqs[x], reverse=True)[0]\n",
    "            majority_classes.append(majority_class)\n",
    "            for attr in discrete_attributes:\n",
    "                data[attr], self.mins_steps[attr] = self.discretize_list(data[attr])\n",
    "            \n",
    "            self.trees.append(self.build_tree(sample_data, sample_data, feature_names, \\\n",
    "                                              label_name, \\\n",
    "                                              majority_class, majority_class))\n",
    "\n",
    "        self.RF_majority_class = max(set(majority_classes), key=majority_classes.count)\n",
    "        \n",
    "        \n",
    "    # creating the decision tree\n",
    "    def build_tree(self, data, original_data, feature_names, label_name, \\\n",
    "                      majority_class, parent_node_class=None):\n",
    "        # if data set contains no features to train with, return parent node class\n",
    "        if len(feature_names) == 0:\n",
    "            #print(\"1:\", parent_node_class)\n",
    "            return parent_node_class\n",
    "        # if subset is empty, ie. no samples, return majority class of original data\n",
    "        elif len(data[label_name]) == 0:\n",
    "            #print(\"2:\", majority_class)\n",
    "            return majority_class\n",
    "        # if data is pure, return the majority class of subset\n",
    "        elif len(list(set( data[label_name] ))) <= 1:\n",
    "            #print(\"3:\", '3'+list(set( data[label_name] ))[0])\n",
    "            return list(set( data[label_name] ))[0]\n",
    "        # if none of the above are true, construct a branch:\n",
    "        else:\n",
    "            # determine parent node class of current branch\n",
    "            class_freqs = dict( (i, data[label_name].count(i)) for i in \\\n",
    "                         list(set( data[label_name] )) )\n",
    "            parent_node_class = sorted(class_freqs, key=lambda x : class_freqs[x], reverse=True)[0]\n",
    "\n",
    "            # determine information gain values for each feature\n",
    "            # choose feature which best splits the data, ie. highest value\n",
    "            gains = dict( (feature, self.information_gain(data, feature, label_name)) for \\\n",
    "                               feature in feature_names ) \n",
    "            best_feature = sorted(gains, key=lambda x : gains[x], reverse=True)[0]\n",
    "\n",
    "            # create tree structure, empty at first\n",
    "            tree = {best_feature: {}}\n",
    "\n",
    "            # remove best feature from available features, it will become the parent node\n",
    "            #feature_names.remove(best_feature)\n",
    "            feature_names = [i for i in feature_names if i != best_feature]\n",
    "\n",
    "            # create nodes under parent node\n",
    "            for value in list(set( data[best_feature] )): #or original_data[best_feature]\n",
    "                new_branch_data = self.data_filter(data, best_feature, value)\n",
    "\n",
    "                # call the algorithm recursively\n",
    "                new_branch = self.build_tree(new_branch_data, original_data, feature_names, \\\n",
    "                                           label_name, majority_class, parent_node_class)\n",
    "\n",
    "                # add subtree to original tree\n",
    "                tree[best_feature][value] = new_branch\n",
    "\n",
    "            return tree\n",
    "\n",
    "\n",
    "    # making prediction for an unseen instance using created tree\n",
    "    def classify(self, instance, current_tree):\n",
    "        # map instance data to tree\n",
    "        for attribute in list(instance.keys()):\n",
    "            # check if feature exists in tree\n",
    "            if attribute in list(current_tree.keys()):\n",
    "                try:\n",
    "                    result = current_tree[attribute][instance[attribute]]\n",
    "                except:\n",
    "                    return self.RF_majority_class\n",
    "\n",
    "                result = current_tree[attribute][instance[attribute]]\n",
    "\n",
    "                # if more attributes exist within result, recursively find best result\n",
    "                if isinstance(result, dict):\n",
    "                    return self.classify(instance, result)\n",
    "                else:\n",
    "                    return result\n",
    " \n",
    "\n",
    "    # take a list of instances to classify\n",
    "    def test(self, test_data, discrete_attributes):\n",
    "        predictions = []\n",
    "\n",
    "        # make a prediction for every instance\n",
    "        feature_names = list(test_data.keys())\n",
    "        length = len(test_data[ feature_names[0] ])\n",
    "        for i in range(length):\n",
    "            test_instance = { feature:test_data[feature][i] for feature in feature_names }\n",
    "\n",
    "            for attr in discrete_attributes:\n",
    "                test_instance[attr] = self.discretize_value(self.mins_steps[attr][0], \\\n",
    "                                                            self.mins_steps[attr][1], \\\n",
    "                                                            test_instance[attr])\n",
    "            votes = []\n",
    "            for tree in self.trees:\n",
    "                votes.append(self.classify(test_instance, tree))\n",
    "                \n",
    "            predictions.append(max(set(votes), key=votes.count))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def discretize_list(self, l):\n",
    "        min_value = min(l)\n",
    "        step = ( max(l) - min(l) ) / 10\n",
    "        ranges = []\n",
    "        for i in range(10):\n",
    "            ranges.append(min_value + (i * step))\n",
    "\n",
    "        new_l = []\n",
    "        for value in l:\n",
    "            new_value = 10\n",
    "            for index_range in zip(range(len(ranges)), ranges):\n",
    "                if value < index_range[1]:\n",
    "                    new_value = index_range[0]\n",
    "                    break\n",
    "            new_l.append(new_value)\n",
    "        return new_l, (min_value, step)\n",
    "\n",
    "\n",
    "    def discretize_value(self, min_value, step, value):\n",
    "        ranges = []\n",
    "        for i in range(10):\n",
    "            ranges.append(min_value + (i * step))\n",
    "\n",
    "        new_value = 10\n",
    "        for index_range in zip(range(len(ranges)), ranges):\n",
    "            if value < index_range[1]:\n",
    "                new_value = index_range[0]\n",
    "                return new_value\n",
    "        return new_value\n",
    "\n",
    "\n",
    "    # make a new sample from the data with the same length with replacement\n",
    "    def sampling(self, data):\n",
    "        #seed(1)\n",
    "        new_data = {}\n",
    "        for key in list(data.keys()):\n",
    "            new_data[key] = []\n",
    "\n",
    "        length = len(data[list(data.keys())[0]])\n",
    "        for i in range(length):\n",
    "            index = randint(0, length-1)\n",
    "            for key in data.keys():\n",
    "                new_data[key].append(data[key][index])\n",
    "\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610727b3",
   "metadata": {},
   "source": [
    "# breast-cancer-wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0ea93",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc7448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6902654867256637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=10)\n",
    "y = df[10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = RF()\n",
    "classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1657d",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe3b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.6496350364963503\n",
      "fold:  2 ===> accuracy:  0.6496350364963503\n",
      "fold:  3 ===> accuracy:  0.6496350364963503\n",
      "fold:  4 ===> accuracy:  0.6544117647058824\n",
      "fold:  5 ===> accuracy:  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./breast-cancer-wisconsin.data', header=None)\n",
    "# drop rows with missing values, missing = ?\n",
    "df = df.replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "\n",
    "target = df[10]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=10)\n",
    "        y = train[10]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=10)\n",
    "        y_test = test[10]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "\n",
    "        classifier = RF()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a9c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31b94531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0024110947709128448\n",
      "Mean:  0.6500751395448691\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f786925",
   "metadata": {},
   "source": [
    "# car dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71af997",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61372ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176882661996497"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./car.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=6)\n",
    "y = df[6]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = RF()\n",
    "classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848ccbb",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6f8d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.9190751445086706\n",
      "fold:  2 ===> accuracy:  0.8786127167630058\n",
      "fold:  3 ===> accuracy:  0.930635838150289\n",
      "fold:  4 ===> accuracy:  0.9130434782608695\n",
      "fold:  5 ===> accuracy:  0.9101449275362319\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.8872832369942196\n",
      "fold:  2 ===> accuracy:  0.9219653179190751\n",
      "fold:  3 ===> accuracy:  0.9161849710982659\n",
      "fold:  4 ===> accuracy:  0.8985507246376812\n",
      "fold:  5 ===> accuracy:  0.9188405797101449\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.9046242774566474\n",
      "fold:  2 ===> accuracy:  0.8959537572254336\n",
      "fold:  3 ===> accuracy:  0.9075144508670521\n",
      "fold:  4 ===> accuracy:  0.9043478260869565\n",
      "fold:  5 ===> accuracy:  0.8956521739130435\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.9364161849710982\n",
      "fold:  2 ===> accuracy:  0.9190751445086706\n",
      "fold:  3 ===> accuracy:  0.8757225433526011\n",
      "fold:  4 ===> accuracy:  0.9043478260869565\n",
      "fold:  5 ===> accuracy:  0.9130434782608695\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.9046242774566474\n",
      "fold:  2 ===> accuracy:  0.8988439306358381\n",
      "fold:  3 ===> accuracy:  0.9104046242774566\n",
      "fold:  4 ===> accuracy:  0.9043478260869565\n",
      "fold:  5 ===> accuracy:  0.9188405797101449\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.8901734104046243\n",
      "fold:  2 ===> accuracy:  0.8959537572254336\n",
      "fold:  3 ===> accuracy:  0.9190751445086706\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.9159420289855073\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.9132947976878613\n",
      "fold:  2 ===> accuracy:  0.9219653179190751\n",
      "fold:  3 ===> accuracy:  0.9017341040462428\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.9072463768115943\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.8815028901734104\n",
      "fold:  2 ===> accuracy:  0.8959537572254336\n",
      "fold:  3 ===> accuracy:  0.9046242774566474\n",
      "fold:  4 ===> accuracy:  0.8927536231884058\n",
      "fold:  5 ===> accuracy:  0.881159420289855\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.8872832369942196\n",
      "fold:  2 ===> accuracy:  0.9104046242774566\n",
      "fold:  3 ===> accuracy:  0.9104046242774566\n",
      "fold:  4 ===> accuracy:  0.9101449275362319\n",
      "fold:  5 ===> accuracy:  0.9072463768115943\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.8815028901734104\n",
      "fold:  2 ===> accuracy:  0.884393063583815\n",
      "fold:  3 ===> accuracy:  0.9161849710982659\n",
      "fold:  4 ===> accuracy:  0.9246376811594202\n",
      "fold:  5 ===> accuracy:  0.8869565217391304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = pd.read_csv('./car.data', header=None)\n",
    "target = df[6]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=6)\n",
    "        y = train[6]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=6)\n",
    "        y_test = test[6]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "\n",
    "        classifier = RF()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fada265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d70deeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.014272021946090613\n",
      "Mean:  0.904282818128508\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084c53d",
   "metadata": {},
   "source": [
    "# mushroom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3e939",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c58c1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "del d_demo[11]\n",
    "del d_demo[16]\n",
    "del d_test[11]\n",
    "del d_test[16]\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = RF()\n",
    "classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5c2a3",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36886eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  1.0\n",
      "fold:  2 ===> accuracy:  1.0\n",
      "fold:  3 ===> accuracy:  1.0\n",
      "fold:  4 ===> accuracy:  1.0\n",
      "fold:  5 ===> accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./mushroom.data', header=None)\n",
    "target = df[0]\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=0)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=0)\n",
    "        y_test = test[0]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "        \n",
    "        del d_demo[11]\n",
    "        del d_demo[16]\n",
    "        del d_test[11]\n",
    "        del d_test[16]\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "\n",
    "        classifier = RF()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b0df804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43f6962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.0\n",
      "Mean:  1.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de48215",
   "metadata": {},
   "source": [
    "# ecoli dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7c3e2",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eb6d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAT_ECOLI</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEA_ECOLI</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEK_ECOLI</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACKA_ECOLI</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADI_ECOLI</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3    4     5     6     7   8\n",
       "0   AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35  cp\n",
       "1  ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44  cp\n",
       "2  ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46  cp\n",
       "3  ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36  cp\n",
       "4   ADI_ECOLI  0.23  0.32  0.48  0.5  0.55  0.25  0.35  cp"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ca733df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40540540540540543"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=8)\n",
    "y = df[8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "del d_demo[0]\n",
    "del d_test[0]\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = [1, 2, 5, 6, 7]\n",
    "\n",
    "\n",
    "classifier = RF()\n",
    "classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d826907",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82190636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 1================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 2================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 3================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 4================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 5================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 6================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 7================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 8================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n",
      "================Run 9================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahman/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 ===> accuracy:  0.4264705882352941\n",
      "fold:  2 ===> accuracy:  0.43283582089552236\n",
      "fold:  3 ===> accuracy:  0.43283582089552236\n",
      "fold:  4 ===> accuracy:  0.417910447761194\n",
      "fold:  5 ===> accuracy:  0.417910447761194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('./ecoli.data', header=None)\n",
    "target = df[8]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        \n",
    "        X = train.drop(columns=8)\n",
    "        y = train[8]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=8)\n",
    "        y_test = test[8]\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        del d_demo[0]\n",
    "        del d_test[0]\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = [1, 2, 5, 6, 7]\n",
    "\n",
    "        classifier = RF()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a7deb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90a9fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.006757162296275413\n",
      "Mean:  0.4255926251097454\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e090228",
   "metadata": {},
   "source": [
    "# letter-recognition dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a319c0",
   "metadata": {},
   "source": [
    "## One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a4199d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7086363636363636"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "mins_steps = {}\n",
    "# organize data into input and output\n",
    "X = df.drop(columns=0)\n",
    "y = df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "d_demo = pd.concat([X_train, y_train], axis=1).to_dict(orient='list')\n",
    "d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "feature_names = list(d_demo.keys())\n",
    "label_name = feature_names[-1]\n",
    "discrete_attributes = []\n",
    "\n",
    "classifier = RF()\n",
    "classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "my_pred = classifier.test(d_test, discrete_attributes)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994820a",
   "metadata": {},
   "source": [
    "## 50 runs (10 * 5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a31e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Run 0================\n",
      "fold:  1 ===> accuracy:  0.73425\n",
      "fold:  2 ===> accuracy:  0.73575\n",
      "fold:  3 ===> accuracy:  0.734\n",
      "fold:  4 ===> accuracy:  0.7455\n",
      "fold:  5 ===> accuracy:  0.7325\n",
      "================Run 1================\n",
      "fold:  1 ===> accuracy:  0.735\n",
      "fold:  2 ===> accuracy:  0.74125\n",
      "fold:  3 ===> accuracy:  0.746\n",
      "fold:  4 ===> accuracy:  0.743\n",
      "fold:  5 ===> accuracy:  0.73975\n",
      "================Run 2================\n",
      "fold:  1 ===> accuracy:  0.736\n",
      "fold:  2 ===> accuracy:  0.7425\n",
      "fold:  3 ===> accuracy:  0.72375\n",
      "fold:  4 ===> accuracy:  0.74125\n",
      "fold:  5 ===> accuracy:  0.73475\n",
      "================Run 3================\n",
      "fold:  1 ===> accuracy:  0.73675\n",
      "fold:  2 ===> accuracy:  0.73675\n",
      "fold:  3 ===> accuracy:  0.7295\n",
      "fold:  4 ===> accuracy:  0.73875\n",
      "fold:  5 ===> accuracy:  0.74475\n",
      "================Run 4================\n",
      "fold:  1 ===> accuracy:  0.74725\n",
      "fold:  2 ===> accuracy:  0.7405\n",
      "fold:  3 ===> accuracy:  0.7405\n",
      "fold:  4 ===> accuracy:  0.737\n",
      "fold:  5 ===> accuracy:  0.736\n",
      "================Run 5================\n",
      "fold:  1 ===> accuracy:  0.7305\n",
      "fold:  2 ===> accuracy:  0.739\n",
      "fold:  3 ===> accuracy:  0.75425\n",
      "fold:  4 ===> accuracy:  0.7425\n",
      "fold:  5 ===> accuracy:  0.7355\n",
      "================Run 6================\n",
      "fold:  1 ===> accuracy:  0.7415\n",
      "fold:  2 ===> accuracy:  0.74325\n",
      "fold:  3 ===> accuracy:  0.72925\n",
      "fold:  4 ===> accuracy:  0.74325\n",
      "fold:  5 ===> accuracy:  0.72875\n",
      "================Run 7================\n",
      "fold:  1 ===> accuracy:  0.74\n",
      "fold:  2 ===> accuracy:  0.74\n",
      "fold:  3 ===> accuracy:  0.747\n",
      "fold:  4 ===> accuracy:  0.72725\n",
      "fold:  5 ===> accuracy:  0.73425\n",
      "================Run 8================\n",
      "fold:  1 ===> accuracy:  0.7455\n",
      "fold:  2 ===> accuracy:  0.73825\n",
      "fold:  3 ===> accuracy:  0.72075\n",
      "fold:  4 ===> accuracy:  0.735\n",
      "fold:  5 ===> accuracy:  0.749\n",
      "================Run 9================\n",
      "fold:  1 ===> accuracy:  0.732\n",
      "fold:  2 ===> accuracy:  0.74625\n",
      "fold:  3 ===> accuracy:  0.74575\n",
      "fold:  4 ===> accuracy:  0.73\n",
      "fold:  5 ===> accuracy:  0.72375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = pd.read_csv('./letter-recognition.data', header=None)\n",
    "target = df[0]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accs = []\n",
    "for run in range(10):\n",
    "    print(\"================Run {}================\".format(run))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "\n",
    "        X = train.drop(columns=0)\n",
    "        y = train[0]\n",
    "        d_demo = pd.concat([X, y], axis=1).to_dict(orient='list')\n",
    "        \n",
    "        X_test = test.drop(columns=0)\n",
    "        y_test = list(test[0])\n",
    "        d_test = X_test.to_dict(orient=\"list\")\n",
    "\n",
    "        feature_names = list(d_demo.keys())\n",
    "        label_name = feature_names[-1]\n",
    "        discrete_attributes = []\n",
    "\n",
    "        classifier = RF()\n",
    "        classifier.train(d_demo, label_name, discrete_attributes, 10)\n",
    "        my_pred = classifier.test(d_test, discrete_attributes)\n",
    "\n",
    "        print(\"fold: \", fold_no, \"===>\", \"accuracy: \", accuracy_score(y_test, my_pred))\n",
    "        accs.append(accuracy_score(y_test, my_pred))\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0c3b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bae9e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  0.007023059685560049\n",
      "Mean:  0.73791\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Standard deviation: \", statistics.stdev(accs) )\n",
    "print(\"Mean: \", statistics.mean(accs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25a4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
